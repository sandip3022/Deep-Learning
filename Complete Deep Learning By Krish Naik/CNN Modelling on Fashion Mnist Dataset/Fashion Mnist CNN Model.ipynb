{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1be18b",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a396474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f896165",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41402f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 9s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images,train_labels),(test_images,test_lables) = fashion.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c2ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f1761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dd3ec07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a9349a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACA0lEQVR4nFWQu24TQRiFz1x31+u1TWQ7IQZZEVESRUghUgouAolIFJQgwQNQIKBAKA1vAS2vwgsgCqChSxGBAnGcZLHsOBvvzM4Mxa5v08yv8+nMmf8A+Qk/fH1TjM8+vysmkl+fHrDu5tnh/mDhrqwclQ9fHkzh7vu4QoJG6fj7jt/vNv/Vzp8AAAUAPPqltDvrHKSbo7jX0vQv7k3hsoK2nop7g9iWknPD3H0A4ABAK/2+D87LXAnKqbiEXZs4V2ige6pEJfN9DWJdctGaOJdSS36zIQkzq3liVacUxY3TwlnveI/ZUepGyWWaWN29fTPBxvjZRvlhe6ffsIpaGfiLKtnalluTPdsf375oRQMJSrJw0Tzfa71Kpw0BT1//UZxwimSF7RYaBQDCBH4OHRWwlrikCjA2gc5kGEKJjIE6/0ID1kwbAoPINDecEBvY/XEaHWe2tI8wgxOa4No8dLijJU09GGEQNAu5gBY3MinBGeBrrMPNQOp403MEHnXUUL0OOwMJKnGgpKbghHG+Cktm4fXIedJJj7gAmRK5Pv7tRjUpK84DqNBzfhVkFi54uppxR0VS5UwsYS5zRZGwL1ExKgooieadJg2UdmHDSlDD3HymMuLEpsL03JBajPJdeAHXarp2RdYrq83tLxFRuciLgr7VT9JTs3z1h9d2ya3j3Pkfp1jNMwZc6WUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import array_to_img\n",
    "array_to_img(train_images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37bc09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(len(train_images),28,28,1)\n",
    "test_images = test_images.reshape(len(test_images),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "848fd1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(\n",
    "            filters=hp.Int('conv_1_filter',min_value=32, max_value=128, step=16),\n",
    "            kernel_size=hp.Choice('conv_1_kernal',values=[3,5]),\n",
    "            activation='relu',\n",
    "            input_shape=(28,28,1)\n",
    "        ),\n",
    "        keras.layers.Conv2D(\n",
    "        filters = hp.Int('conv_2_filter',min_value=32,max_value=64,step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernal',values=[3,5]),\n",
    "        activation='relu'\n",
    "            ,),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units',min_value=32,max_value=128,step=16),\n",
    "        activation='relu'\n",
    "        ),\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer = keras.optimizers.Adam(hp.Choice('learning_rate',\n",
    "                                                             values=[1e-2,1e-3])),\n",
    "                 loss=\"sparse_categorical_crossentropy\",\n",
    "                 metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abfd26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine import hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c3a3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search = RandomSearch(build_model,\n",
    "                           objective=\"val_accuracy\",\n",
    "                           max_trials=5,directory='output',\n",
    "                           project_name=\"Mnist Fashion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7b47e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 08m 16s]\n",
      "val_accuracy: 0.10499999672174454\n",
      "\n",
      "Best val_accuracy So Far: 0.21449999511241913\n",
      "Total elapsed time: 00h 39m 20s\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(train_images,train_labels,epochs=3,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ee63c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "383b4c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 22, 48)        38448     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23232)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 112)               2602096   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2640864 (10.07 MB)\n",
      "Trainable params: 2640864 (10.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd744684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 130s 76ms/step - loss: 11.0789 - accuracy: 0.2042 - val_loss: 10.8610 - val_accuracy: 0.2145\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 134s 79ms/step - loss: 11.0789 - accuracy: 0.2042 - val_loss: 10.8610 - val_accuracy: 0.2145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1db06a51cf0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, validation_split=0.1, initial_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22153092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
